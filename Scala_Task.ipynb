{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{StructType, IntegerType, StringType, DateType, DoubleType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@25db74cb\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@25db74cb"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "  .builder\n",
    "  .appName(\"myapp\")\n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(id,IntegerType,true), StructField(name,StringType,true), StructField(email,StringType,true), StructField(joinDate,DateType,true), StructField(status,StringType,true))\n",
       "df_customer = [id: int, name: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, name: string ... 3 more fields]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = new StructType()\n",
    "      .add(\"id\", IntegerType, true)\n",
    "      .add(\"name\", StringType, true)\n",
    "      .add(\"email\", StringType, true)\n",
    "      .add(\"joinDate\", DateType, true)\n",
    "      .add(\"status\", StringType, true)\n",
    "\n",
    "val df_customer = spark.read.format(\"csv\")\n",
    "      .options(Map(\"delimiter\"->\"\\\\t\"))\n",
    "      .schema(schema)\n",
    "      .load(\"customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(id,IntegerType,true), StructField(name,StringType,true), StructField(price,DoubleType,true), StructField(numberOfProducts,IntegerType,true))\n",
       "df_product = [id: int, name: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, name: string ... 2 more fields]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = new StructType()\n",
    "      .add(\"id\", IntegerType, true)\n",
    "      .add(\"name\", StringType, true)\n",
    "      .add(\"price\", DoubleType, true)\n",
    "      .add(\"numberOfProducts\", IntegerType, true)\n",
    "\n",
    "val df_product = spark.read.format(\"csv\")\n",
    "      .options(Map(\"delimiter\"->\"\\\\t\"))\n",
    "      .schema(schema)\n",
    "      .load(\"product.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(customerID,IntegerType,true), StructField(orderID,IntegerType,true), StructField(productID,IntegerType,true), StructField(numberOfProduct,IntegerType,true), StructField(orderDate,DateType,true), StructField(orderStatus,StringType,true))\n",
       "df_order = [customerID: int, orderID: int ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[customerID: int, orderID: int ... 4 more fields]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = new StructType()\n",
    "      .add(\"customerID\", IntegerType, true)\n",
    "      .add(\"orderID\", IntegerType, true)\n",
    "      .add(\"productID\", IntegerType, true)\n",
    "      .add(\"numberOfProduct\", IntegerType, true)\n",
    "      .add(\"orderDate\", DateType, true)\n",
    "      .add(\"orderStatus\", StringType, true)\n",
    "\n",
    "val df_order = spark.read.format(\"csv\")\n",
    "      .options(Map(\"delimiter\"->\"\\\\t\"))\n",
    "      .schema(schema)\n",
    "      .load(\"order.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_joined = [customerID: int, name: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[customerID: int, name: string ... 6 more fields]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_joined = df_customer.join(df_order, df_customer(\"id\") === df_order(\"customerID\"), \"inner\").select(\n",
    "    \"customerID\", \n",
    "    \"name\", \n",
    "    \"orderDate\", \n",
    "    \"status\", \n",
    "    \"orderID\", \n",
    "    \"productID\", \n",
    "    \"numberOfProduct\", \n",
    "    \"orderStatus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+-------+---------+---------------+-----------+\n",
      "|customerID|     name| orderDate|  status|orderID|productID|numberOfProduct|orderStatus|\n",
      "+----------+---------+----------+--------+-------+---------+---------------+-----------+\n",
      "|         1|     John|2018-02-23|  active|     21|        3|            500|  delivered|\n",
      "|         1|     John|2018-02-23|  active|     22|        1|            300|  delivered|\n",
      "|         1|     John|2018-02-23|  active|     23|        2|            300|  delivered|\n",
      "|         1|     John|2018-03-23|  active|     24|        1|            500|  delivered|\n",
      "|         1|     John|2018-03-23|  active|     25|        2|            300|  delivered|\n",
      "|         1|     John|2018-03-23|  active|     26|        3|            300|  delivered|\n",
      "|         1|     John|2018-04-23|  active|     27|        1|            400|  delivered|\n",
      "|         1|     John|2018-04-23|  active|     28|        2|            200|  delivered|\n",
      "|         1|     John|2018-04-23|  active|     29|        3|            200|  delivered|\n",
      "|         1|     John|2018-05-23|  active|     30|        1|            200|   canceled|\n",
      "|         1|     John|2018-05-23|  active|     31|        2|             50|   canceled|\n",
      "|         1|     John|2018-05-23|  active|     32|        3|             50|   canceled|\n",
      "|         2|   Philip|2017-10-16|  active|     33|        1|            100|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     34|        2|            100|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     35|        3|            200|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     36|        4|             50|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     37|        5|             50|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     38|        6|             50|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     39|        7|             50|  delivered|\n",
      "|         2|   Philip|2017-10-16|  active|     40|        8|             50|  delivered|\n",
      "|         2|   Philip|2018-04-16|  active|     41|        1|            200|  delivered|\n",
      "|         2|   Philip|2018-04-16|  active|     42|        2|            200|  delivered|\n",
      "|         2|   Philip|2018-04-16|  active|     44|        8|            200|  delivered|\n",
      "|         3|   Vasili|2018-05-01|  banned|     45|        1|            100|  delivered|\n",
      "|         3|   Vasili|2018-06-01|  banned|     54|        1|            200|   canceled|\n",
      "|         3|   Vasili|2018-06-01|  banned|     55|        2|            200|   canceled|\n",
      "|         3|   Vasili|2018-06-01|  banned|     56|        3|            100|   canceled|\n",
      "|         4|Anastasia|2018-05-01|  active|     57|        1|            200|  delivered|\n",
      "|         4|Anastasia|2018-05-01|  active|     58|        2|            200|  delivered|\n",
      "|         4|Anastasia|2018-05-01|  active|     59|        3|            200|  delivered|\n",
      "|         4|Anastasia|2018-06-01|  active|     60|        1|            200|  delivered|\n",
      "|         4|Anastasia|2018-06-01|  active|     61|        2|            200|  delivered|\n",
      "|         4|Anastasia|2018-07-01|  active|     62|        1|            100|  delivered|\n",
      "|         4|Anastasia|2018-07-01|  active|     63|        2|            100|  delivered|\n",
      "|         4|Anastasia|2018-08-01|  active|     64|        3|            100|   canceled|\n",
      "|         4|Anastasia|2018-08-01|  active|     65|        3|            100|  delivered|\n",
      "|         5|   Robert|2017-11-01|canceled|     66|        4|            200|  delivered|\n",
      "|         5|   Robert|2017-11-01|canceled|     67|        5|            200|  delivered|\n",
      "|         5|   Robert|2017-12-01|canceled|     68|        4|            200|  delivered|\n",
      "|         5|   Robert|2017-12-02|canceled|     69|        5|            200|  delivered|\n",
      "|         5|   Robert|2018-01-01|canceled|     70|        4|            200|  delivered|\n",
      "|         5|   Robert|2018-01-01|canceled|     71|        5|            100|  delivered|\n",
      "|         5|   Robert|2018-02-01|canceled|     72|        4|            100|  delivered|\n",
      "|         5|   Robert|2018-02-02|canceled|     73|        5|            100|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     74|        1|            200|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     75|        2|            200|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     76|        3|            300|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     77|        4|            100|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     78|        5|            100|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     79|        6|             50|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     80|        7|             50|  delivered|\n",
      "|         6|     Sara|2017-07-21|  active|     81|        8|           1000|  delivered|\n",
      "+----------+---------+----------+--------+-------+---------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// df_joined.groupBy(\"customerID\", \"productID\").sum(\"numberOfProduct\").as(\"sum_salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.createOrReplaceTempView(\"EMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_client_product = [customer_name: string, productID: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[customer_name: string, productID: int]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df_client_product = spark.sql(\"\"\"\n",
    "    SELECT distinct m.name as customer_name, m.productID\n",
    "    FROM\n",
    "        (SELECT\n",
    "            n.name,\n",
    "            n.productID,\n",
    "            n.summary,\n",
    "            MAX(n.summary) over (Partition By n.name) as popular\n",
    "        FROM\n",
    "            (SELECT \n",
    "            name, \n",
    "            productID, \n",
    "            SUM(\n",
    "                case \n",
    "                    when orderStatus = 'delivered' then numberOfProduct\n",
    "                    else 0\n",
    "                end\n",
    "            ) over (Partition By name, productID) as summary \n",
    "            FROM EMP\n",
    "            ) n\n",
    "        ) m\n",
    "    WHERE summary = popular\n",
    "    ORDER BY customer_name\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|customer_name|productID|\n",
      "+-------------+---------+\n",
      "|    Anastasia|        1|\n",
      "|    Anastasia|        2|\n",
      "|         John|        1|\n",
      "|       Philip|        1|\n",
      "|       Philip|        2|\n",
      "|       Robert|        4|\n",
      "|         Sara|        8|\n",
      "|       Vasili|        1|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_client_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_joined_final = [customer.name: string, product.name: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[customer.name: string, product.name: string]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_joined_final = df_client_product\n",
    "    .join(df_product, df_client_product(\"productID\") === df_product(\"id\"), \"inner\")\n",
    "    .select(col(\"customer_name\").as(\"customer.name\"), col(\"name\").as(\"product.name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|customer.name|     product.name|\n",
      "+-------------+-----------------+\n",
      "|    Anastasia|   Apple iPhone 7|\n",
      "|    Anastasia|   Apple iPhone 8|\n",
      "|         John|   Apple iPhone 7|\n",
      "|       Philip|   Apple iPhone 7|\n",
      "|       Philip|   Apple iPhone 8|\n",
      "|       Robert|Apple iPad mini 4|\n",
      "|         Sara|    Apple AirPods|\n",
      "|       Vasili|   Apple iPhone 7|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources\n",
    "\n",
    "https://sparkbyexamples.com/spark/spark-read-csv-file-into-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Toree - Scala",
   "language": "scala",
   "name": "spark_-_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
